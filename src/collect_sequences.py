# src/collect_sequences.py
# เก็บคลิป landmarks (T เฟรม) สำหรับเทรน LSTM ตามคลาสที่กำหนด
# รองรับระบุผู้เก็บ (--user) และมือ (--hand) → เซฟเป็น dataset/sequences/<label>/<user>/<hand>/*.npy
# มีตัวช่วยนับ "นิ้วยก" เพื่อกรองตามคลาส, mirror x ให้มือซ้ายเป็นแกนมือขวา

import os
import cv2
import time
import json
import argparse
import numpy as np
import mediapipe as mp
from collections import deque
from datetime import datetime
from pathlib import Path

# ================ CONFIG =================
CLASSES = [
    "desktop_left", "desktop_right",          # 5 นิ้วปัด ซ้าย/ขวา
    "tab_left", "tab_right",                  # 3 นิ้วปัด ซ้าย/ขวา
    "scroll_left", "scroll_right",            # 2 นิ้วปัด ซ้าย/ขวา
    "scroll_up", "scroll_down",               # 2 นิ้วปัด ขึ้น/ลง
    "screenshot",                             # 5 นิ้วแบ -> กำมือ (ในคลิปเดียวกัน)
    "idle"                                    # พักมือ/ไม่มีท่า (สำคัญมาก)
]

# ปุ่มลัดเลือกคลาส
KEYMAP = {
    'a': "desktop_left",   'd': "desktop_right",
    'j': "tab_left",       'l': "tab_right",
    'h': "scroll_left",    'n': "scroll_right",
    'u': "scroll_up",      'k': "scroll_down",
    'o': "screenshot",
    'z': "idle"
}

# จำนวน “นิ้วยก” ที่คาดหวังของแต่ละคลาส (ใช้กรองตอนบันทึกคลิป)
EXPECTED_FINGERS = {
    "desktop_left": 5,  "desktop_right": 5,  "screenshot": None,
    "tab_left": 3,      "tab_right": 3,
    "scroll_left": 2,   "scroll_right": 2,   "scroll_up": 2,   "scroll_down": 2,
    "idle": None
}

# ยาวคลิป (จำนวนเฟรม/ตัวอย่าง)
T = 30  # แนะนำ 24–40

# โฟลเดอร์ปลายทาง root (ข้างในแบ่ง label/user/hand อัตโนมัติ)
OUT_ROOT = Path("dataset/sequences")

# เกณฑ์เชื่อมั่น mediapipe
MIN_DET, MIN_TRK = 0.6, 0.6

# แสดง hint บนจอ
SHOW_HINT = True
# ========================================

def parse_args():
    ap = argparse.ArgumentParser(description="Collect hand-landmark sequences to .npy")
    ap.add_argument("--user", required=True, help="collector name, e.g., alice")
    ap.add_argument("--hand", choices=["left", "right"], default="right", help="which hand you use")
    ap.add_argument("--camera", type=int, default=0, help="cv2 camera index")
    ap.add_argument("--label", default="idle", help="initial label (use hotkeys to switch)")
    ap.add_argument("--frames", type=int, default=T, help="frames per sequence (T)")
    ap.add_argument("--countdown", type=int, default=2, help="seconds before recording starts")
    ap.add_argument("--min_det", type=float, default=MIN_DET)
    ap.add_argument("--min_trk", type=float, default=MIN_TRK)
    return ap.parse_args()

# ---------- geometry helpers ----------
def angle_between(v1, v2):
    num = np.dot(v1, v2)
    den = np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6
    c = np.clip(num / den, -1.0, 1.0)
    return np.degrees(np.arccos(c))

def is_extended(lm2d, tip, pip_, mcp):
    v1 = np.array([lm2d[tip][0]-lm2d[pip_][0], lm2d[tip][1]-lm2d[pip_][1]])
    v2 = np.array([lm2d[mcp][0]-lm2d[pip_][0], lm2d[mcp][1]-lm2d[pip_][1]])
    ang = angle_between(v1, v2)
    return ang > 160  # ยืด ~ 180°

def count_fingers(lm2d):
    return {
        'thumb':  is_extended(lm2d, 4, 3, 2),
        'index':  is_extended(lm2d, 8, 6, 5),
        'middle': is_extended(lm2d,12,10,9),
        'ring':   is_extended(lm2d,16,14,13),
        'pinky':  is_extended(lm2d,20,18,17),
    }

def expected_finger_hint(label):
    if label in ("desktop_left", "desktop_right"):
        return "ใช้ 5 นิ้ว ปัดซ้าย/ขวา"
    if label in ("tab_left", "tab_right"):
        return "ใช้ 3 นิ้ว (ชี้+กลาง+นาง) ปัดซ้าย/ขวา"
    if label in ("scroll_left", "scroll_right", "scroll_up", "scroll_down"):
        return "ใช้ 2 นิ้ว (ชี้+กลาง) ปัดตามทิศ"
    if label == "screenshot":
        return "แบมือ 5 นิ้ว → กำมือ ในคลิปเดียวกัน"
    if label == "idle":
        return "มืออยู่นิ่ง/ไม่ออกท่า"
    return ""

def save_meta(root: Path, T_value: int):
    root.mkdir(parents=True, exist_ok=True)
    meta_path = root / "_meta.json"
    with meta_path.open("w", encoding="utf-8") as f:
        json.dump(
            {"T": T_value, "classes": CLASSES, "expected_fingers": EXPECTED_FINGERS},
            f, ensure_ascii=False, indent=2
        )

def ensure_dirs(label: str, user: str, hand: str) -> Path:
    d = OUT_ROOT / label / user / hand
    d.mkdir(parents=True, exist_ok=True)
    return d

def save_clip(label: str, user: str, hand: str, clip_np: np.ndarray) -> str:
    """
    บันทึกเป็น .npy: shape = (T, 63)
    path: dataset/sequences/<label>/<user>/<hand>/clip_YYYYmmdd_HHMMSS_xxxxxx.npy
    """
    out_dir = ensure_dirs(label, user, hand)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    out_path = out_dir / f"clip_{ts}.npy"
    np.save(out_path.as_posix(), clip_np.astype(np.float32))
    return out_path.as_posix()

# --------------- Main ---------------
def main():
    args = parse_args()
    T_local = int(args.frames)

    # เตรียมโฟลเดอร์ + meta
    save_meta(OUT_ROOT, T_local)
    for c in CLASSES:
        # เตรียมโฟลเดอร์ระดับ label เฉย ๆ (user/hand จะสร้างตอน save)
        (OUT_ROOT / c).mkdir(parents=True, exist_ok=True)

    mp_hands = mp.solutions.hands
    mp_draw = mp.solutions.drawing_utils
    mp_styles = mp.solutions.drawing_styles

    cap = cv2.VideoCapture(args.camera)
    if not cap.isOpened():
        raise RuntimeError("Cannot open camera")

    print(f"[INFO] Collector: {args.user}  Hand: {args.hand}  T={T_local}")
    print("[INFO] Hotkeys: A/D desktop  J/L tab  H/N scroll←/→  U/K scroll↑/↓  O screenshot  Z idle  |  S start/stop  Q quit")

    buf = deque(maxlen=T_local)
    current = args.label if args.label in CLASSES else "idle"
    recording = False
    saved = {c: 0 for c in CLASSES}
    prev_tip = None

    with mp_hands.Hands(
        model_complexity=0,
        max_num_hands=1,
        min_detection_confidence=args.min_det,
        min_tracking_confidence=args.min_trk
    ) as hands:

        while True:
            ok, frame = cap.read()
            if not ok:
                break
            frame = cv2.flip(frame, 1)
            h, w = frame.shape[:2]
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            res = hands.process(rgb)

            status = f"[{current}] user:{args.user}/{args.hand}  REC:{'ON' if recording else 'OFF'}  saved:{saved[current]}"
            cv2.putText(frame, status, (10, 28),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                        (0, 220, 255) if recording else (255, 255, 255), 2)

            if SHOW_HINT:
                hint = expected_finger_hint(current)
                if hint:
                    cv2.putText(frame, hint, (10, 56),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.65, (200, 255, 200), 2)

            if res.multi_hand_landmarks:
                hand = res.multi_hand_landmarks[0]

                # ตรวจฝั่งมือจาก MediaPipe ("Left"/"Right")
                handed_label = None
                if res.multi_handedness:
                    handed_label = res.multi_handedness[0].classification[0].label

                # landmarks → pts_2d + vec63 (mirror x ถ้ามือซ้าย)
                pts_2d = []
                vec63 = []
                for i in range(21):
                    x = hand.landmark[i].x
                    y = hand.landmark[i].y
                    z = hand.landmark[i].z
                    if handed_label == "Left":
                        x = 1.0 - x  # canonicalize left->right
                    pts_2d.append((x, y))
                    vec63.extend([x, y, z])
                vec63 = np.array(vec63, dtype=np.float32)

                # วาดโครงมือ
                mp_draw.draw_landmarks(
                    frame, hand, mp_hands.HAND_CONNECTIONS,
                    mp_styles.get_default_hand_landmarks_style(),
                    mp_styles.get_default_hand_connections_style()
                )

                # นับนิ้วยก
                fingers = count_fingers(pts_2d)
                num_up = int(sum(fingers.values()))
                cv2.putText(frame, f"Fingers up: {num_up}", (10, 86),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 0), 2)

                # อัดคลิป
                if recording:
                    need = EXPECTED_FINGERS.get(current)
                    ok_to_record = True if need is None else (num_up == need)

                    if ok_to_record:
                        buf.append(vec63)

                    # แถบ progress
                    cv2.rectangle(frame, (10, h-30), (10 + int((len(buf)/T_local)*(w-20)), h-10), (0, 200, 0), -1)
                    cv2.rectangle(frame, (10, h-30), (w-10, h-10), (255, 255, 255), 2)

                    if len(buf) == T_local:
                        clip_np = np.stack(list(buf), axis=0)  # (T,63)
                        out_path = save_clip(current, args.user, args.hand, clip_np)
                        saved[current] += 1
                        buf.clear()
                        cv2.putText(frame, f"Saved: {Path(out_path).name}", (10, h-46),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                # ลูกศรทิศ (ช่วยเตือน)
                tip = np.array(pts_2d[8], dtype=np.float32)
                if prev_tip is not None and SHOW_HINT:
                    delta = tip - prev_tip
                    cxy = (int(tip[0]*w), int(tip[1]*h))
                    exy = (int((tip[0]+delta[0]*3)*w), int((tip[1]+delta[1]*3)*h))
                    cv2.arrowedLine(frame, cxy, exy, (100, 255, 100), 2, tipLength=0.4)
                prev_tip = tip.copy()

            else:
                prev_tip = None  # reset เมื่อไม่เห็นมือ

            # แถบคีย์ลัด
            cv2.putText(frame,
                        "A/D desktop  J/L tab  H/N scroll<- ->  U/K scroll^ v  O screenshot  Z idle  |  S start/stop  Q quit",
                        (10, h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (240, 240, 240), 1)

            cv2.imshow(f"Collect Sequences (T={T_local})", frame)
            k = cv2.waitKey(1) & 0xFF
            if k == ord('q'):
                break
            elif k == ord('s'):
                # เคลียร์บัฟ/เริ่ม-หยุด
                buf.clear()
                if not recording and args.countdown > 0:
                    # countdown ก่อนเริ่ม
                    t0 = time.time()
                    while time.time() - t0 < args.countdown:
                        ok2, frame2 = cap.read()
                        if not ok2: break
                        frame2 = cv2.flip(frame2, 1)
                        remain = args.countdown - int(time.time() - t0)
                        cv2.putText(frame2, f"Recording in {remain}", (10, 120),
                                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,200,255), 3)
                        cv2.imshow(f"Collect Sequences (T={T_local})", frame2)
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            cap.release(); cv2.destroyAllWindows(); return
                recording = not recording
            elif chr(k).lower() in KEYMAP:
                current = KEYMAP[chr(k).lower()]
                buf.clear()

    cap.release()
    cv2.destroyAllWindows()
    print("[INFO] Saved counts:", {k: int(v) for k, v in saved.items()})

if __name__ == "__main__":
    main()
